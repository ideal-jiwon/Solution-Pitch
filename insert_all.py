import pandas as pd
import psycopg2
from psycopg2.extras import execute_values
from app.services.db import connect_db


def insert_businesses(csv_path):
    df = pd.read_csv(csv_path)
    conn = connect_db()
    cursor = conn.cursor()

    df["hours"] = df["hours"].apply(lambda h: None if pd.isna(h) or h == "\\N" else h)
    df["is_open"] = df["is_open"].apply(lambda x: str(x).lower() == "true")

    values = [
        (
            str(row["business_id"]),
            str(row["name"]),
            str(row["address"]),
            str(row["city"]),
            str(row["state"]),
            str(row["postal_code"]),
            float(row["latitude"]),
            float(row["longitude"]),
            str(row["categories"]),
            row["hours"],
            int(row["review_count"]),
            float(row["stars"]),
            bool(row["is_open"])
        )
        for _, row in df.iterrows()
    ]

    query = """
        INSERT INTO businesses (
            business_id, name, address, city, state, postal_code,
            latitude, longitude, categories, hours,
            review_count, stars, is_open
        ) VALUES %s
        ON CONFLICT (business_id) DO NOTHING;
    """
    execute_values(cursor, query, values, page_size=1000)
    conn.commit()
    cursor.close()
    conn.close()
    print("âœ… businesses ì‚½ì… ì™„ë£Œ")

def insert_reviews(csv_path):
    conn = connect_db()
    cursor = conn.cursor()

    chunk_size = 10000

    try:
        for chunk in pd.read_csv(csv_path, chunksize=chunk_size):
            chunk.dropna(subset=["review_id"], inplace=True)
            chunk.drop_duplicates(subset=["review_id"], inplace=True)

            # ì•ˆì „í•œ íƒ€ì… ë³€í™˜
            chunk.fillna({
                "text": "",
                "stars": 0,
                "useful": 0,
                "funny": 0,
                "cool": 0
            }, inplace=True)

            chunk["stars"] = pd.to_numeric(chunk["stars"], errors="coerce").fillna(0).astype(int)
            chunk["useful"] = pd.to_numeric(chunk["useful"], errors="coerce").fillna(0).astype(int)
            chunk["funny"] = pd.to_numeric(chunk["funny"], errors="coerce").fillna(0).astype(int)
            chunk["cool"] = pd.to_numeric(chunk["cool"], errors="coerce").fillna(0).astype(int)
            chunk["place_id"] = chunk.get("place_id", "UNKNOWN")

            values = [
                (
                    str(row["review_id"]),
                    str(row["business_id"]),
                    int(row["stars"]),
                    str(row["date"]),
                    str(row["text"]),
                    int(row["useful"]),
                    int(row["funny"]),
                    int(row["cool"]),
                    str(row["place_id"])
                )
                for _, row in chunk.iterrows()
            ]

            query = """
                INSERT INTO reviews (
                    review_id, business_id, stars, date,
                    text, useful, funny, cool, place_id
                ) VALUES %s;
            """

            try:
                # ğŸ” ë””ë²„ê¹…ìš© ì¶œë ¥
                print("ì¿¼ë¦¬ í™•ì¸:", query)
                print("ì˜ˆì‹œ values:", values[0])

                execute_values(
                    cursor,
                    query,
                    values,
                    template="(%s, %s, %s, %s, %s, %s, %s, %s, %s)",  # ğŸ‘ˆ í•µì‹¬!!
                    page_size=1000
                )
                conn.commit()
                print(f"âœ… ì²­í¬ {len(values)}ê±´ ì‚½ì… ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ì²­í¬ ì‚½ì… ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
                conn.rollback()

    finally:
        cursor.close()
        conn.close()
        print("âœ… ì „ì²´ reviews ì‚½ì… ì‘ì—… ì¢…ë£Œ")




if __name__ == "__main__":
    insert_businesses("/Users/stellam/Desktop/temp/business.csv")
    insert_reviews("/Users/stellam/Desktop/temp/review.csv")
